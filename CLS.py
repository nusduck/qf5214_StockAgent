import requests
import time
import csv
import os
import pandas as pd
from datetime import datetime, timedelta

# è®¾ç½®è¯·æ±‚å¤´
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# è®¾ç½®çˆ¬å–æ—¶é—´èŒƒå›´ï¼ˆä»ä¸Šå‘¨åˆ°ç°åœ¨ï¼‰
start_time = int((datetime.now() - timedelta(days=7)).timestamp())  # 7å¤©å‰çš„æ—¶é—´æˆ³
end_time = int(time.time())  # å½“å‰æ—¶é—´æˆ³

# CSV æ–‡ä»¶è·¯å¾„
csv_file = "/Users/caidanni/Desktop/news_data.csv"

# è®°å½•å·²çˆ¬å–çš„æ–°é—»ï¼Œé¿å…é‡å¤
seen_news = set()

# å¦‚æœ CSV æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
if not os.path.exists(csv_file):
    with open(csv_file, "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["æ—¶é—´", "æ ‡é¢˜", "é“¾æ¥"])  # ä¿®æ”¹è¡¨å¤´

# æœ€å¤§çˆ¬å–é¡µæ•°
max_pages = 5  # æ§åˆ¶çˆ¬å–æ·±åº¦
current_page = 1

while current_page <= max_pages:
    url = f"https://www.cls.cn/nodeapi/updateTelegraphList?app=CailianpressWeb&category=&hasFirstVipArticle=1&lastTime={start_time}&os=web&rn=20&subscribedColumnIds=&sv=8.4.6&_t={int(time.time())}"
    
    try:
        response = requests.get(url, headers=headers, timeout=10).json()
    except Exception as e:
        print(f"è¯·æ±‚å¤±è´¥: {e}, ä¼‘æ¯ 10 ç§’åé‡è¯•")
        time.sleep(10)
        continue

    # è§£æ API è¿”å›çš„æ•°æ®
    if "data" in response and "roll_data" in response["data"] and response["data"]["roll_data"]:
        news_list = response["data"]["roll_data"]
        news_data = []

        for news in news_list:
            news_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(news["ctime"]))  # è½¬æ¢æ—¶é—´æ ¼å¼
            title = news.get("title", "æ— æ ‡é¢˜")

            # **æå– URL é“¾æ¥**
            news_url = news.get("share_url") or news.get("shareurl") or "æ— é“¾æ¥"  # ä¼˜å…ˆè·å– `share_url`

            # é¿å…é‡å¤çˆ¬å–ç›¸åŒæ–°é—»
            if title not in seen_news:
                seen_news.add(title)
                news_data.append([news_time, title, news_url])  # è¿½åŠ æ•°æ®

        # **å†™å…¥ CSV**
        if news_data:
            df = pd.DataFrame(news_data, columns=["æ—¶é—´", "æ ‡é¢˜", "é“¾æ¥"])
            df.to_csv(csv_file, mode="a", encoding="utf-8", index=False, header=False)
            print(f"ğŸ“Œ æˆåŠŸå†™å…¥ {len(news_data)} æ¡æ–°é—»ï¼ˆç¬¬ {current_page} é¡µï¼‰")

        # æ›´æ–° last_timeï¼Œç»§ç»­çˆ¬å–æ›´æ—©çš„æ•°æ®
        start_time = news_list[-1]["ctime"]
        current_page += 1
        time.sleep(2)  # é¿å…é¢‘ç¹è¯·æ±‚
    else:
        print(f"âš ï¸ ç¬¬ {current_page} é¡µæ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
        break

print("âœ… çˆ¬å–å®Œæˆï¼Œæ•°æ®å·²å†™å…¥ CSV æ–‡ä»¶ï¼")
